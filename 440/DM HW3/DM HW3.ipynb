{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC440-Data Mining Homework 3 (Written by Haoshu Qin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due: 02/26/2023\n",
    "\n",
    "Description:\n",
    "Market Basket Analysis (Chapter 6) is commonly used in \"recommender\" systems.\n",
    "The basic idea is to discover interesting rules of the form {If someone likes these} -> {then they may also like these}. Download and get to know the Anonymous Microsoft Web Data Data Set:\n",
    "https://archive.ics.uci.edu/ml/datasets/Anonymous+Microsoft+Web+Data\n",
    "\n",
    "All students must perform MBA using the Apriori algorithm.\n",
    "Students enrolled in 440 (Grad students) must in addition also perform analysis using the FP_GROW algorithm and compare the results of the two algorithms.\n",
    "\n",
    "You may use \"library\" functions. The Kagle tutorial is a good resource, but you must apply this to the dataset at hand (https://www.kaggle.com/code/rockystats/apriori-algorithm-or-market-basket-analysis).\n",
    "Submit a pdf \"paper\"/\"report\" describing the problem, your approach to pre-processing, the tools you used, the problems you encountered and your results. Briefly discuss why your results are \"interesting\" and not \"trivial\". Discuss your choice of min_support and confidence. \n",
    "(The target size of the paper is 5 pages, but your mileage may vary.)\n",
    "Only include essential code in the body your paper. Include the full code and sample runs you used as an appendix to the paper.\n",
    "\n",
    "Proper formatting of the paper is essential and counts for the grade. Get familiar with standard ACM (Association for Computing Machinery) standards. \n",
    "Please understand : results are of course important, but proper presentation is also important.\n",
    "For extra credit (30%) implement the algorithms yourself without libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: What is Apriori algorithm ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apriori algorithm is a classic algorithm for frequent itemset mining and association rule learning over transactional databases. It is an unsupervised learning algorithm that tries to discover the underlying relationships and patterns among the items in a large dataset. The Apriori algorithm operates by using a \"bottom up\" approach, starting with individual items and then combining them to form larger itemsets. The algorithm uses two main parameters, support and confidence, to determine which itemsets are considered frequent and which association rules are considered strong. The support of an itemset is defined as the proportion of transactions that contain the itemset, while the confidence of an association rule is defined as the proportion of transactions that contain the antecedent of the rule that also contain the consequent. The Apriori algorithm is widely used in market basket analysis, recommendation systems, and many other data mining tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apriori algorithm is an association rule learning algorithm used to find frequent item sets in large datasets and generate association rules from those item sets. It works by identifying combinations of items in a dataset that occur frequently together, using the concept of \"support\". The support of an item set is defined as the proportion of transactions in the dataset that contain the item set. The algorithm starts by finding all the items that have a support greater than a specified threshold, called the minimum support. These items are then combined to form larger item sets, and the process is repeated until no further frequent item sets can be found. Association rules can then be generated by computing the \"confidence\" of the rules, which is defined as the proportion of transactions containing the antecedent (left-hand side) of the rule that also contain the consequent (right-hand side). The Apriori algorithm is commonly used in market basket analysis and recommendation systems, among other applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: How to implement the algorithm in Python ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "def apriori(transactions, min_support=0.5, min_confidence=0.5):\n",
    "    # Get all unique items in the transactions\n",
    "    unique_items = set(item for transaction in transactions for item in transaction)\n",
    "    # Create a dictionary of item frequency\n",
    "    item_frequency = defaultdict(int)\n",
    "    for transaction in transactions:\n",
    "        for item in unique_items:\n",
    "            if item.issubset(transaction):\n",
    "                item_frequency[item] += 1\n",
    "    # Filter items that meet the minimum support\n",
    "    frequent_items = [item for item, count in item_frequency.items() if count/len(transactions) >= min_support]\n",
    "    # Apriori Property: Any subset of a frequent itemset must be frequent\n",
    "    frequent_items = set(frequent_items)\n",
    "    frequent_item_sets = [frequent_items]\n",
    "    while frequent_items:\n",
    "        frequent_items = [item.union(set([new_item])) for item in frequent_items\n",
    "                         for new_item in unique_items if new_item not in item and\n",
    "                         item.union(set([new_item])) in frequent_item_sets[-1]]\n",
    "        frequent_items = [item for item in frequent_items if item_frequency[item]/len(transactions) >= min_support]\n",
    "        frequent_item_sets.append(frequent_items)\n",
    "    # Generate the association rules\n",
    "    association_rules = []\n",
    "    for frequent_item_set in frequent_item_sets:\n",
    "        for item in frequent_item_set:\n",
    "            if len(item) > 1:\n",
    "                for sub_item in itertools.combinations(item, len(item) - 1):\n",
    "                    sub_item = set(sub_item)\n",
    "                    confidence = item_frequency[item]/item_frequency[sub_item]\n",
    "                    if confidence >= min_confidence:\n",
    "                        association_rules.append((sub_item, item.difference(sub_item), confidence))\n",
    "    return frequent_item_sets, association_rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this implementation, the transactions argument is a list of sets, where each set represents a transaction and its items. The min_support argument is the minimum support threshold, which determines the minimum frequency of an itemset to be considered frequent. The min_confidence argument is the minimum confidence threshold, which determines the minimum confidence of an association rule.\n",
    "\n",
    "The algorithm returns a list of frequent item sets and a list of association rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: How to implement the algorithm without any libraries in Python ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(transactions, min_support=0.5, min_confidence=0.5):\n",
    "    item_count = defaultdict(int)\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            item_count[item] += 1\n",
    "    frequent_items = set([item for item, count in item_count.items() if count/len(transactions) >= min_support])\n",
    "    frequent_item_sets = [frequent_items]\n",
    "    for k in range(2, len(frequent_items) + 1):\n",
    "        candidate_item_sets = set([frozenset(x) for x in itertools.combinations(frequent_items, k)])\n",
    "        frequent_item_sets_k = set()\n",
    "        for transaction in transactions:\n",
    "            for candidate_item_set in candidate_item_sets:\n",
    "                if candidate_item_set.issubset(transaction):\n",
    "                    item_count[candidate_item_set] += 1\n",
    "        for candidate_item_set, count in item_count.items():\n",
    "            if count/len(transactions) >= min_support:\n",
    "                frequent_item_sets_k.add(candidate_item_set)\n",
    "        if not frequent_item_sets_k:\n",
    "            break\n",
    "        frequent_item_sets.append(frequent_item_sets_k)\n",
    "        frequent_items = set([item for item_set in frequent_item_sets_k for item in item_set])\n",
    "    association_rules = []\n",
    "    for frequent_item_set in frequent_item_sets:\n",
    "        for item_set in frequent_item_set:\n",
    "            if len(item_set) > 1:\n",
    "                for item in item_set:\n",
    "                    sub_item_set = item_set - set([item])\n",
    "                    confidence = item_count[item_set]/item_count[sub_item_set]\n",
    "                    if confidence >= min_confidence:\n",
    "                        association_rules.append((sub_item_set, item_set - sub_item_set, confidence))\n",
    "    return frequent_item_sets, association_rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation follows the same logic as the previous implementation, but uses the built-in Python data structures such as defaultdict and set to achieve the same result. The algorithm takes a list of transactions, where each transaction is a list of items, and returns a list of frequent item sets and a list of association rules. The min_support and min_confidence arguments are used to control the minimum frequency and minimum confidence of the output, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/4np1mkyd1c11qp8qktvl2v4r0000gn/T/ipykernel_27538/2488638832.py:1: DtypeWarning: Columns (2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data1 = pd.read_csv('/Users/haydee_mac/Desktop/CSC440-Data Mining/DM HW3/anonymous-msweb.data')\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv('/Users/haydee_mac/Desktop/CSC440-Data Mining/DM HW3/anonymous-msweb.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>4</th>\n",
       "      <th>www.microsoft.com</th>\n",
       "      <th>created by getlog.pl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <th>1</th>\n",
       "      <td>VRoot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VRoot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">N</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <th>2</th>\n",
       "      <td>Hide1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">V</th>\n",
       "      <th>1035</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <th>42711</th>\n",
       "      <td>42711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <th>1008</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131665 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             I    4 www.microsoft.com created by getlog.pl\n",
       "T 1      VRoot    0                 0                VRoot\n",
       "N 0          0  NaN               NaN                  NaN\n",
       "  1          1  NaN               NaN                  NaN\n",
       "T 2      Hide1    0                 0                 Hide\n",
       "N 0          0  NaN               NaN                  NaN\n",
       "...        ...  ...               ...                  ...\n",
       "V 1035       1  NaN               NaN                  NaN\n",
       "  1001       1  NaN               NaN                  NaN\n",
       "  1018       1  NaN               NaN                  NaN\n",
       "C 42711  42711  NaN               NaN                  NaN\n",
       "V 1008       1  NaN               NaN                  NaN\n",
       "\n",
       "[131665 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"sepal_length\", 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "iris = pd.read_csv(\"iris.data\", header = 0, names=column_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
